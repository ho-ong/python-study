{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNDgjubUK66ZAyQTcvJ78cp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Machine Learning**"],"metadata":{"id":"b-a_I9m_hKxz"}},{"cell_type":"markdown","source":["**빅데이터**\n","\n","*   대량의 정형, 반정형, 비정형 데이터로부터 가치를 추출 하고 결과를 분석하는 기술이다.\n","*   정형 데이터 : 행과 열의 구조를 가진다. (Database, Spreadsheet)\n","*   반정형 데이터 : XML, JSON 등\n","*   비정형 데이터 : 텍스트, 이미지, 오디오, 비디오 등\n","*   오픈 데이터(Publish Data) : Kaggle, Dacon, AIHub, 공공데이터포털(data.go.kr)"],"metadata":{"id":"SFr8DwjohWdm"}},{"cell_type":"markdown","source":["**데이터 저장**\n","\n","*   정형, 반정형, 비정형 데이터 저장한다.\n","*   Database, Excel, Image 등"],"metadata":{"id":"Uil6mHv0iKmS"}},{"cell_type":"markdown","source":["**데이터 분석**\n","\n","*   머신러닝, 딥러닝, 통계, 텍스트 분석한다.\n","*   데이터를 통해 다각도의 분석 및 다양한 추론을 도출한다.\n","*   분류, 회귀 등"],"metadata":{"id":"DoDA-mZ3idv_"}},{"cell_type":"markdown","source":["**데이터 활용**\n","\n","*   데이터 가시화 및 결론 도출한다.\n","*   히스토그램, 플롯 등\n","*   그래프 분석 : 시각화를 통해서 탐색적, 직관적 이해에 도움을 주고, 의사결정에 기여한다.\n","  1. Bar Chart : 빈도수와 범주형 Data를 표현한다. (x축 : 범주형 데이터, y축 : 빈도 수)\n","  2. Histrogram : 도수 분포를 그래프로 표현한다. (x축 : 구간, y축 : 도수)\n","  3. Box Plot : 데이터의 분포를 파악하기 용이하다.\n","  4. Pie Chart : 요소별 구성 비율을 원형 그래프에 나타낸 것이다.\n","  5. Scatter Plot : x축의 데이터와 y축의 데이터 간의 관계를 표현한다. (x축 : 연속형, y축 : 연속형)\n","  6. Scatter Matrix : 여러 개의 변수를 pair하게 관계를 나타낸 그래프이다.\n","  7. Heatmap : 값의 정도에 따라 색상이\n","  바뀌는 그래프이다. (상관 분석)\n","  8. Trend Chart : 시간에 따른 X축의 값에 따라 Y축이 어떻게 바뀌는지 나타낸다."],"metadata":{"id":"iCtV0B6kii3p"}},{"cell_type":"markdown","source":["**Machine Learning 통계 기초**"],"metadata":{"id":"AfIwjyhQjutu"}},{"cell_type":"markdown","source":["**통계를 배우는 이유**\n","\n","*   21세기에 데이터가 기하 급수적으로 늘어남에 따라 데이터를 토대로 분석 및 가설 검증 등으로 수준 높은 서비스 및 경영 수준이 향상했다.\n","*   이에 따라 데이터를 분석 가능한 인재 요구 및 통계 구술 면접 빈번하다."],"metadata":{"id":"XmVm4kQ9jwmB"}},{"cell_type":"markdown","source":["**데이터 분석**\n","\n","*   데이터 분석에는 크게 AI, 통계기법 등으로 구분할 수 있다.\n","*   AI 내에서 통계가 사용되는 예\n","  1. 결측치 처리\n","  2. feature selection\n","  3. 회귀\n","  4. 가시화(Visualization) 분석"],"metadata":{"id":"oG7IA9VEosLM"}},{"cell_type":"markdown","source":["**통계**\n","\n","*   통계는 특정 집단을 대상으로 한 조사나 실험 또는 수집 데이터에 의해 구한 결과에 요약된 형태의 표현이다."],"metadata":{"id":"4AUTnJcbo3bN"}},{"cell_type":"markdown","source":["**통계학**\n","\n","*   불확실성이 내포된 데이터의 추정, 검정, 예측을 통하여 의사결정에 필요한 정보의 획득과 처리방법을 연구하는 학문이다.\n","*   추정 : 대상 집단의 특성값이 무엇일까?\n","*   검정 : 가설을 세우고 그 가설이 맞는지 확인한다."],"metadata":{"id":"p6DLOyRCo-P1"}},{"cell_type":"markdown","source":["**데이터 유형**\n","\n","*   연속형(Continuous) : 나누어질 수 있고, 연속적으로 측정 되는 것이다. (온도, 키, 무게)\n","*   이산형(Discrete), 범주형 : 나누어질 수 없음, 수치로 측정이 불가능한 자료이다. (성별, 합/불합, 등급)"],"metadata":{"id":"pgJ_Xh-JpX9t"}},{"cell_type":"markdown","source":["**연속형 데이터**\n","\n","*   등간척도(Interval) : 같은 간격을 가지지만 진정한 영점이 없는 척도이다. (온도)\n","*   비율척도(Ratio) : 절대적 기준값 (0)이 존재하는 척도 (무게, 나이)"],"metadata":{"id":"BBYGmpwopioH"}},{"cell_type":"markdown","source":["**이산형 데이터**\n","\n","*   명목척도(Norminal): 관찰대상의 속성에 따라 관찰대상을 상호배타적으로 구분한다.\n","*   예 : (성별, 합/불합)\n","*   순위척도(Ordinal): 관찰대상이 가지고 있는 속성 크기에 따라 관찰대상의 순위, 서열을 부여하는 데이터이다.\n","*   예 : (만족도(1, 2, 3, 4, 5), 학교성적등급(1등, 2등))"],"metadata":{"id":"by_mXY_xpsny"}},{"cell_type":"markdown","source":["**모집단, 표본**\n","\n","*   모수 : 모집단의 분포의 특징을 나타내는 대표값이다.\n","*   통계량 : 표본분포의 특징을 나타내는 대표값이다."],"metadata":{"id":"38J9PLF4p2vM"}},{"cell_type":"markdown","source":["**모집단에서 표본 추출하는 방법**\n","\n","*   무작위(랜덤) 샘플링\n","*   층별화된 무작위(랜덤) 샘플링\n","*   계통적 샘플링\n","*   서브그룹 샘플링"],"metadata":{"id":"SQuhQ5tGrE7i"}},{"cell_type":"markdown","source":["**통계 기호**"],"metadata":{"id":"lvpID9_grUdQ"}},{"cell_type":"markdown","source":["**기술 통계**\n","\n","*   데이터의 속성을 특정한 통계량을 사용해 정리, 요약하는 방법이다.\n","1. 중심 척도 : 산술평균, 중위값, 최빈치\n","2. 산포 척도 : 분산, 표준편차, 범위\n","3. 분포 모양 : 빈도, 상대도수, 누적도수, 비대칭도(왜도), 첨도"],"metadata":{"id":"67qnw5qcrXFH"}},{"cell_type":"markdown","source":["**중심 경향 통계량 : 산술평균, 중앙값, 최빈값**\n","\n","*   산술평균 : 관측치의 총합을 관측치 개수로 나눈 값이다. (Outlier에 민감하다.)\n","*   중앙값 : 데이터를 크기순으로 정렬한 후, 중앙에 위치한 값이다. (Outlier에 영향을 덜 받는다.)\n","*   최빈값 : 데이터에서 빈도수가 가장 많이 발생한 값이다."],"metadata":{"id":"UXuk4-B9rv65"}},{"cell_type":"markdown","source":["**산포 : 데이터가 퍼져 있는 정도를 설명, 범위, 분산, 표준편차, 사분위수 범위(IQR)**\n","\n","*   범위 : 데이터 max값 - 데이터 min값\n","*   분산 : 평균에서 각 데이터까지의 거리를 제곱한 수치의 평균이다.\n","*   표준편차(Standard Deviation 또는 std) : 분산에 제곱근을 취한 값이다.\n","*   사분위수 범위(IQR, Interquartile Range) : 사분위범위 = 3사분위수 - 1사분위수 (박스플롯 해석에 사용)"],"metadata":{"id":"JqqRRpFzr-3t"}},{"cell_type":"markdown","source":["**분포 모양: 데이터가 퍼져있는 형태를 나타내는 것**\n","\n","*   도수 분포 : 도수, 상태\n","*   비대칭도(왜도, Skewness) : 분포가 치우쳐진 정도이다.\n","*   첨도 : 분포모양이 뾰족한 정도이다."],"metadata":{"id":"rlzSS87LsWPk"}},{"cell_type":"markdown","source":["**상관분석 : 두 변수간의 선형적 관계의 강도와 방향을 분석하는 통계기법**\n","\n","*   공분산\n","  *   둘 이상의 변량이 연관성을 가지며 분포하는 모양을 전체적으로 나타낸 분산이다.\n","  *   두 변수가 동일한 방향으로 움직일 때 (두 변수 모두 증가하거나 또는 감소할 때), 공분산은 크고, 양의 값을 가진다.\n","  *   두 변수가 반대방향으로 움직일 때, 공분산은 크고, 음의 값을 가진다.\n","*   상관계수\n","  *   두 변수 간의 선형적인 관계의 정도와 방향을 수치로 나타낸다."],"metadata":{"id":"bh-KwKxVse_F"}},{"cell_type":"markdown","source":["**Machine Learning 이론**"],"metadata":{"id":"aoQe5gRBs-SW"}},{"cell_type":"markdown","source":["**Machine Learning**\n","\n","*   대용량의 Data로부터 이들 Data 내에 존재하는 관계, 패턴, 규칙 등을 탐색하고, 변수들간의 관련성을 찾아내어 모형화(수학적 함수, 논리적 구조 또는 모델)함으로써 유용한 지식을 추출하는 일련의 과정을 의미한다.\n","*   머신러닝의 종류\n","  *   회귀 : feature를 이용해 타깃수치를 예측하는 것이다. (몸무게 featur를 통하여 칼로리 예측)\n","  *   분류 : 특정 Case가 어디에 속하는지를 결정한다. (양품/불량, 스팸/정상)\n","  *   군집 : 여러 속성의 Data를 비교하여 유사한 속성을 갖는 Data를 함께 그룹화시키는 것이다. (고객 세분화)\n","  *   연관 : 한 패턴의 출현이 다른 패턴의 출현을 암시하는 특성이나 항목간의 관계를 파악한다. (장바구니 분석)"],"metadata":{"id":"RXgoZWOA0JfG"}},{"cell_type":"markdown","source":["**지도학습 종류(Supervised)**\n","\n","*   K-최근접이웃(K-nearst Neighbors)\n","*   선형회귀\n","*   로지스틱회귀\n","*   서포터벡터머신(Support Vector Machine, SVM)\n","*   결정트리(Decision Tree, 의사결정나무), 랜덤포레스트"],"metadata":{"id":"EOZ6uSCv0OqG"}},{"cell_type":"markdown","source":["**비지도학습 종류(Unsupervised)**\n","\n","*   군집(Clustering) : K-means, Hierachical Cluster\n","*   주성분분석 : t-SNE(t-distributed Stochastic Neighbor Embedding)"],"metadata":{"id":"wlZBjoVD0eoG"}},{"cell_type":"markdown","source":["**준지도학습(Semi Supervised)**\n","\n","*   (레이블이 없는 데이터 + 레이블이 있는 데이터)의 훈련"],"metadata":{"id":"0SVs5jSo0jRK"}},{"cell_type":"markdown","source":["**머신러닝 프로세스**\n","\n","*   데이터 전처리 -> 데이터 Split -> 모델 및 평가지표 정의 -> 모델 훈련 -> 모델 평가(오차 측정) -> Figure"],"metadata":{"id":"oJam0LVq04Vc"}},{"cell_type":"markdown","source":["**데이터 전처리**"],"metadata":{"id":"p6ZOHuO54G5V"}},{"cell_type":"markdown","source":["**데이터 전처리**\n","\n","*   Table, Text, Time Series 형태 - N개의 데이터가 있다.\n","*   Image 형태 - 차원 : (데이터 개수, 채널, 가로, 세로)"],"metadata":{"id":"ioS5pvoa1HnR"}},{"cell_type":"markdown","source":["**결측치**\n","\n","*   값이 없는 경우, Nan 또는 Null 값을 지칭한다."],"metadata":{"id":"UXnoKfJy1hUG"}},{"cell_type":"markdown","source":["**결측치 조치**\n","\n","*   대체값 : 평균, 0, 중간값\n","*   몸무게 열 삭제\n","*   김철수 데이터 삭제\n","*   선형 보간법\n","*   Generative Model 이용"],"metadata":{"id":"mtYH_5rE1uTA"}},{"cell_type":"markdown","source":["**Feature rescaling**\n","\n","*   키(height)와 몸무게(weight) 변수가 있다고 하면 단위는 각각 (cm, kg)이며 관찰한 표 본이 성인이라고 가정할 때 범위는 (150-190cm), (40-100kg) 정도로 다른 단위와 범위를 가지게 된다.\n","*   Min max Normalization : 값을 0~1사이로 스케일링 한다.\n","*   Robust Normalization : 사분위값을 이용하므로 이상치에 영향을 덜 받는다.\n","*   표준화 (Standardization) : mean 차감을 통해 zero-centered화를 시켜주고, std로 나누어줌으로써 데이터가 일정 범위 안에 머무르게 하며, 이상치의 영향을 덜 받는다. (정규분포 공부 필요)\n","*   로지스틱 회귀나 트리 기반 모델인 의사결정나무, 랜덤 포레스트 , 그래디언트 부스팅은 변수의 크기에 민감하지 않으므로 스케일링을 수행할 필요가 없다."],"metadata":{"id":"9WKOauJ71uYS"}},{"cell_type":"markdown","source":["**데이터 Split**"],"metadata":{"id":"QMan7_a33xQ4"}},{"cell_type":"markdown","source":["**모델링 데이터 구조**\n","\n","*   모델을 만들기 위한 학습용 데이터와 모델링 결과를 평가하기 위한 평가용 데이터를 구분하는 것을 의미한다.\n","*   Hold Out 기법 : 보통 Train Data와 Validation Data를 8:2로 나눈다.\n","*   Test 데이터의 개념 : 일반화 성능(Generalization performance)을 측정한다.\n","*   K-Fold Cross Validation 기법\n","*   Leave-one-out cross-validation 기법\n","*   Repeated random sub-sampling validation 기법"],"metadata":{"id":"_BjqRz_e4LNU"}},{"cell_type":"markdown","source":["**모델 및 평가지표 정의**"],"metadata":{"id":"slNb6Jh05GSw"}},{"cell_type":"markdown","source":["**모델**\n","\n","*   데이터를 가지고 학습하고자 하는 수학적 모델이다.\n","*   Parameter = Learnable Parameter"],"metadata":{"id":"yynSs8fV4rxQ"}},{"cell_type":"markdown","source":["**선형회귀(Linear Regression)**\n","\n","*   단일 회귀 : feature가 1개일 때\n","*   다중 회귀 : feature가 p개일 때\n","*   다항 회귀 : n차 방정식"],"metadata":{"id":"GNUScF5m5YMr"}},{"cell_type":"markdown","source":["**선형회귀 훈련**\n","\n","*   예측값이 얼마나 틀렸는가? : 손실함수(Loss Function, Cost Function)\n","*   손실함수를 알기 전에 : Norm (노름, 놈)\n","*   L1 Norm, L2 Norm"],"metadata":{"id":"p2nZv_jy7NsJ"}},{"cell_type":"markdown","source":["**L1 Norm 과 L2 Norm 의 차이**\n","\n","*   검정색 두 점사이의 L1 Norm은 빨간색, 파란색, 노란색 선으로 표현 될 수 있고, L2 Norm은 오직 초록색 선으로만 표현한다.\n","*   L2 Loss는 직관적으로 오차의 제곱을 더하기 때문에 Outlier에 더 큰 영향을 받는다.\n","*   L1 Loss가 L2 Loss에 비해 Outlier 에 대하여 더 Robust(덜 민감 혹은 둔감)하다.\n","*   Outlier가 적당히 무시되길 원한다면 L1 Loss를 사용하고, Outlier의 등장에 신경써야 하는 경우라면 L2 Loss를 사용하는 것이 좋다."],"metadata":{"id":"_WOVM6DU7dSQ"}},{"cell_type":"markdown","source":["**회귀 손실함수(Loss Function, Cost Function)**\n","\n","*   Mean Absolute Error(MAE)\n","*   Mean Square Error(MSE)\n","*   Root Mean"],"metadata":{"id":"6EWsPeVe7z51"}},{"cell_type":"markdown","source":["**Parameter Update = 모델 업데이트 또는 최적화**\n","\n","*   경사하강법(Gradient Descent) : Optimizer의 한 종류이다.\n","*   분류 문제는 Cross Entrophy를 미분하여 사용한다.\n","*   배치 경사하강법은 매번 스텝마다 모든 데이터의 Gradient를 사용해서 느리다.\n","*   확률적 경사하강법 : 딱한개의 샘플을 무작위로 선택하고 그 하나의 Gradient를 계산한다.\n","*   미니배치 경사하강법 : Train Data의 일부 세트로 Gradient를 계산한다."],"metadata":{"id":"lPIjwkFd_0zO"}},{"cell_type":"markdown","source":["**모델 훈련**"],"metadata":{"id":"nhCMj-CqhhiJ"}},{"cell_type":"markdown","source":["**과대적합, 과소적합(Overfitting, Underfitting)**\n","\n","*   과대적합\n","  *   Train 데이터에 너무 지나치게 학습한 경우이다.\n","  *   모델 평가시 Train데이터에서는 성능이 우수, 허나, Validation 성능에서는 나쁘다.\n","*   과소적합\n","  *   Train 데이터에서 학습을 제대로 못한 경우이다.\n","  *   Train성능 저조, Validation 성능 저조하다."],"metadata":{"id":"kXVc3bAehnz-"}},{"cell_type":"markdown","source":["**과대적합, 과소적합(Overfitting, Underfitting) 문제 해결**\n","\n","*   과대적합\n","  *   데이터 수를 늘리거나, 단순한 모델을 사용한다.\n","  *   규제(Regularization)을 사용한다.\n","*   과소적합\n","  *   좀 더 복잡한 모델을 사용하거나 좋은 feature 선별, 데이터 수를 늘린다.\n","  *   규제를 완화한다.\n","*   딥러닝에서도 같은 방법을 사용한다."],"metadata":{"id":"IPsL1PQ8hzTH"}},{"cell_type":"markdown","source":["**모델 평가 -> Figure**"],"metadata":{"id":"gUnGKYsKiOu4"}},{"cell_type":"markdown","source":["**회귀의 모델 평가방법 : 그래프 분석 및 R2 Score, corr(y, y hat)**\n","\n","*   SST(Total Sum of Squares) : 회귀 평균과 개별 자료 간의 편차 제곱합.\n","*   SSR(Regression Sum of Squares) : 회귀 평균과 적합선 예측값 간의 편차 제곱 합. 설명변수에 의해 설명되는 변동.\n","*   SSE(Error Sum of Squares) : 적합선 예측값과 개별 자료 간의 편차 제곱합. 오차로 인해 설명되지 않는 변동.\n","*   결정계수(R^2, Coefficient of determination)"],"metadata":{"id":"OoSLr-LdiRLy"}},{"cell_type":"markdown","source":["**분류의 모델 평가방법 : 이진분류에서 양성 음성의 클래스라고 가정**\n","\n","*   정확도의 경우 클래스가 데이터 분류가 균일하지 못하면 머신의 성능을 제대로 나타내줄 수 없기 때문에 F1을 사용한다."],"metadata":{"id":"cqmrzzh5m0SG"}},{"cell_type":"markdown","source":["**Receiver Operating Characteristic curve(ROC Curve)**\n","\n","*   AUC(Area Under the Curve) : 넓을수록 좋다.\n","*   Y축 : True Positive Rate라고도  부른다.\n","*   X축 : False Positive Rate라고도 부른다."],"metadata":{"id":"zbp8C9U_jZf3"}},{"cell_type":"markdown","source":["**Polynomial Regression(다항회귀)**\n","\n","*   어느 정도 꾸불꾸불해야 fitting이 잘된다.\n","*   수학적 기교 : linear model에 feature를 n제곱해서 넣으면 다항회귀가 된다."],"metadata":{"id":"vASmM3Nzjpe6"}},{"cell_type":"markdown","source":["**규제(Regularization)**\n","\n","*   과대적합(Overfitting)을 줄이는 방법 또는 학습을 방해하는 방법이다.\n","*   릿지회귀 : 영향을 거의 미치지 않는 특성에 대하여 0에 가까운 가중치를 준다.\n","*   라쏘회귀 : 특성값의 계수가 매우 낮다면 0으로 수렴하게 하여 특성을 지워버린다.\n","*   엘라스틱넷 : 라쏘회귀와 릿지회귀의 최적화 지점이 서로 다르기 때문에 두 정규화 항을 합쳐서 r로 규제정도를 조절한다.\n","*   사용자가 정해주는 값 : 하이퍼 파라미터"],"metadata":{"id":"bROXOuZ0wopl"}},{"cell_type":"markdown","source":["**조기 종료(Early Stopping)**\n","\n","*   경사 하강법 같은 반복적인 학습 알고리즘에서 에러가 최솟값에 도달하면 바로 훈련을 중지한다."],"metadata":{"id":"fBbwJtXHyTjF"}},{"cell_type":"markdown","source":["**로지스틱 회귀분석**\n","\n","*   로지스틱 함수를 이용해서 분류 하는 것이다.\n","*   시그모이드 함수를 이용한 로지스틱 회귀분석 (이진분류)\n","*   소프트맥스 함수를 이용한 로지스틱 회귀분석 (다중분류)"],"metadata":{"id":"9fgRuO4U3QPT"}},{"cell_type":"markdown","source":["**서포터 벡터 머신(SVM, Support Vector Machine)**\n","\n","*   Support Vector를 통해 두개의 클래스를 가장 잘 분류하는 선분을 찾는 것이다.\n","*   직선으로부터 가장 멀리 떨어진 Support Vector를 찾아야한다. (Large Margin Classification)\n","*   하드 마진 : 완벽히 마진오류가 없이 분류하는 것이다. (일반화 성능 하락)\n","*   소프트 마진 : 어느 정도 마진 오류를 감수하고, margin의 크기를 넓히는 방법이다. (일반화 성능 어느 정도 보장)\n","*   마진 오류 : 샘플이 Margin과 실선 사이에 있거나 반대쪽에 있는 경우이다."],"metadata":{"id":"Uvzy1Jbu3YaP"}},{"cell_type":"markdown","source":["**서포터 벡터 머신 회귀**\n","\n","*   Margin 안에서 최대한 많은 샘플이 들어가도록 학습시킨다. (많은 데이터를 고려해서 fitting)\n","*   엡실론 : margin 넓이 하이퍼 파라미터이다. (모델에 큰 영향 X)"],"metadata":{"id":"9k_JeASE3-E8"}},{"cell_type":"markdown","source":["**결정트리(Decision Tree)**\n","\n","*   분류와 회귀에 사용되는 나무형태의 머신러닝 알고리즘이다.\n","*   강력한 머신러닝 알고리즘 중 하나인 Random Forest의 구성요소이다.\n","  *   루트 노드(Root Node) : 깊이가 0인 맨 꼭대기 노드이다.\n","  *   리프 노드(Leaf node) : 자식 노드를 가지지않는 노드이다.\n","  *   지니 불순도(Gini Impurity) : 한 노드의 샘플이 같은 클래스에 속해있다면 지니불순도는 0이다.\n","  *   CART 알고리즘(Classification and regression Tree) : 임계값을 기준으로 2개의 서브셋을 만든다. 맨 위 루트노드에서 최적의 분할을 찾으며 각 단계에서 과정 반복한다."],"metadata":{"id":"HjBvpF2EEWWi"}},{"cell_type":"markdown","source":["**앙상블 기법**\n","\n","*   여러가지의 모델을 사용해 그 결과를 투표(분류:최빈값), 또는 평균(회귀)을 내어 예측하는 방법이다."],"metadata":{"id":"f9GMSE6kHb9b"}},{"cell_type":"markdown","source":["**배깅, 페이스팅**\n","\n","*   배깅 : 훈련세트에서 중복을 허용하여 샘플링하는 방식이다.\n","*   페이스팅 : 중복을 허용하지 않고 샘플링 하는 방식이다."],"metadata":{"id":"SJBZLRguHnTk"}},{"cell_type":"markdown","source":["**랜덤포레스트**\n","\n","*   배깅 방법을 적용한 결정 트리의 앙상블 기법이다.\n","*   오버피팅에 강력하다."],"metadata":{"id":"UbpALRH-HnfM"}},{"cell_type":"markdown","source":["**부스팅(Boosting)**\n","\n","*   여러 개의 약한 모델을 연결하여 강한 모델을 만드는 앙상블 기법이다.\n","*   앞의 모델을 보완해나가면서(또는 틀렸던 부분에 가중치를 주면서) 모델을 학습시키는 방법이다."],"metadata":{"id":"sYcDc2FJHzMX"}},{"cell_type":"markdown","source":["**AdaBoost(Boosting)**\n","\n","*   아래와 같이 노드 하나에 리프(Leaf)를 지닌 트리를 Stump라고 한다.\n","*   AdaBoost는 아래와 같이 여러 개의 stump로 구성되어있다. (Forest of stumps)\n","*   여러 질문을 통해 데이터를 분류하는 트리와는 다르게, stump는 단 하나의 질문으로 데이터를 분류해야 한다.\n","*   각 Stump는 생성 될 때 이전 stump 정보를 참고한다. 즉 종속적이고 연속적으로 모델이 생성한다."],"metadata":{"id":"pFYQYRrOIEqs"}},{"cell_type":"markdown","source":["**GradientBoost(Boosting)**\n","\n","*   Stump나 Tree가 아닌 하나의 Leaf (Single Leaf)부터 시작한다."],"metadata":{"id":"aC5OIfhtIar-"}},{"cell_type":"markdown","source":["**XGBoost(Boosting)**\n","\n","*   Gradient Boost 알고리즘을 병렬 학습이 지원되도록 구현한 라이브러리이다.\n","*   나무를 만들 때 동시에 서로 다른 가지를 만들어 나간다.\n","*   GBM 대비 빠른 수행시간"],"metadata":{"id":"retsL6R_Igh2"}},{"cell_type":"markdown","source":["**LightGBM**\n","\n","*   XGBoost의 효율성 문제를 보완하여 나온 알고리즘이다.\n","*   빠른 학습 및 예측 수행 시간,더 작은 메모리 사용량\n","*   리프 중심 분할 방식을 이용, 트리의 깊이가 매우 깊어지기 때문에 max_depth에 대한 파라미터 설정이 중요하다."],"metadata":{"id":"qo5zn2y0Ip5R"}},{"cell_type":"markdown","source":["**Stacking**\n","\n","*   모든 모델의 예측을 취합하여 모델을 훈련시킨다.\n","*   Meth model 또는 blender라고 한다."],"metadata":{"id":"RPliPNy6I004"}},{"cell_type":"markdown","source":["**AutoML - Pycaret**\n","\n","*   여러 모델을 한번에 학습하여 비교해주는 라이브러리이다."],"metadata":{"id":"whh8ZdSGJAn4"}}]}