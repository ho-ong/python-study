{"cells":[{"cell_type":"markdown","metadata":{"id":"gabQ8IZe9bxY"},"source":["**1. Deep Neural Nerwork - 다층 퍼셉트론 구현**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VPa-03Z29WUd"},"outputs":[],"source":["# torch는 딥러닝을 구성하기 편하도록 페이스북에서 만든 딥러닝 라이브러리\n","# 텐서플로우랑 똑같은 딥러닝 라이브러리\n","import torch\n","\n","# 신경망 구축을 쉽게 해주는 함수\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3FWqAx-4-HBm"},"outputs":[],"source":["# GPU 확인\n","# GPU가 없으면 CPU로 연산\n","# GPU가 있으면 GPU로 연산하겠다는 준비\n","# 따라서 device는 CPU나 GPU 문자열로 바뀐다.\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iOn_TGCu-2uc"},"outputs":[],"source":["# 4명의 데이터가 있는데, 1명당 2개의 컬럼을 가지고 있다.\n","# 그리고 그걸 2차원 리스트로 4명의 데이터를 선언 후\n","# 토치가 알아먹을 수 있는 텐서타입으로 바꾼다. 이때 텐서타입은 float\n","# to(device)는 모델이 GPU에서 연산될 것이기 떄문에 to(cuba)를 함으로써 데이터를 GPU에 얹혀 놓는다.\n","X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n","Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AgPa1KL_QDJ"},"outputs":[],"source":["model = nn.Sequential(\n","    nn.Linear(2, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n","    nn.Sigmoid(),\n","    nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n","    nn.Sigmoid(),\n","    nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n","    nn.Sigmoid(),\n","    nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n","    nn.Sigmoid()\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdujNtR9_Z4d"},"outputs":[],"source":["criterion = torch.nn.MSELoss().to(device) # Mean Square Error\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n","\n","# 옵티마이저인 Stochastic Gradient Descent를 사용한다.\n","# 업데이트 대상은 model 객체가 가지고 있는 W들을 대상으로 업데이트를 할 것이고, learning rate는 0.001로 설정할 것이다."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4MG2OziFXIf"},"outputs":[],"source":["for epoch in range(50): # 50번 학습할 것이다.\n","  optimizer.zero_grad() # 옵티마이저의 기울기를 매번 초기화 해서 계산해야하기 때문에 초기화하는 함수를 선언\n","  # forward 연산\n","  hypothesis = model(X) # 모델에 데이터를 넣고, propagation을 진행한 후, 최종 아웃풋을 hypothesis에 담는다.\n","\n","  # 비용 함수\n","  cost = criterion(hypothesis, Y) # 예측값과 정답값 사이의 Mean Square Loss를 구한다.\n","  cost.backward() # backpropagtion이 아니다. 이름에 낚이지 말자. 이 부분은 기울기를 구하는 함수다.\n","  optimizer.step() # 여기서 비로소 backpropagation을 실행하여 모델의 모든 w들을 업데이트 한다.\n","  \n","  # 5의 배수에 해당되는 에포크마다 비용을 출력\n","  if epoch % 5 == 0:\n","    print(\"에폭 :\", epoch, cost.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"j2KXo05aFiYH"},"outputs":[],"source":["X_2 = torch.FloatTensor([[0, 0], [0, 1]]).to(device)\n","hypothesis = model(X_2)\n","print(hypothesis)"]},{"cell_type":"markdown","metadata":{"id":"AAh24E7rFmvo"},"source":["**2. minibatch DNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y9GQODu7Hval"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.utils.data import TensorDataset # 텐서데이터셋\n","from torch.utils.data import DataLoader # 데이터로더"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G0LL9mySHzBB"},"outputs":[],"source":["# GPU 확인\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rK7xN1ahH44s"},"outputs":[],"source":["# 5명의 데이터, 각 데이터는 3개의 컬럼(피처)를 갖는다.\n","x_train = torch.FloatTensor(\n","    [[73, 80, 75],\n","    [93, 88, 93],\n","    [89, 91, 90],\n","    [96, 98, 100],\n","    [73, 66, 70]]\n",")\n","\n","# 정답값은 1사람당 1개\n","y_train = torch.FloatTensor([[152], [185], [180], [196], [142]])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HYt46jRrIEUH"},"outputs":[],"source":["# X 데이터셋과 Y 데이터 셋을 포장한다.\n","dataset = TensorDataset(x_train, y_train)\n","print(list(dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FAs6nApQJckQ"},"outputs":[],"source":["# 2개 데이터를 1세트로 만들어서 전체데이터셋을 쪼갠다. 이때 만든 n개의 세트들의 순서를 shuffle 한다.\n","dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdnWKFP2J0el"},"outputs":[],"source":["model = nn.Sequential(\n","    nn.Linear(3, 10, bias=True), # input_layer = 2, hidden_layer1 = 10\n","    nn.ReLU(),\n","    nn.Linear(10, 10, bias=True), # hidden_layer1 = 10, hidden_layer2 = 10\n","    nn.ReLU(),\n","    nn.Linear(10, 10, bias=True), # hidden_layer2 = 10, hidden_layer3 = 10\n","    nn.ReLU(),\n","    nn.Linear(10, 1, bias=True), # hidden_layer3 = 10, output_layer = 1\n","    nn.ReLU()\n",").to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Xv2eraRWJ85U"},"outputs":[],"source":["criterion = torch.nn.MSELoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) # 0.00001"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x28KtZSSKwtT"},"outputs":[],"source":["nb_epochs = 5\n","\n","# 전체 데이터 셋으로 5번 학습할 것이다.\n","for epoch in range(nb_epochs + 1):\n","  # minibatch 데이터를 반환하면서 index도 반환한다.GPU 터질까봐 mini batch를 한다.\n","  for batch_idx, samples in enumerate(dataloader):\n","    x_train, y_train = samples\n","    x_train= x_train.to(device)\n","    y_train= y_train.to(device)\n","\n","    # H(x) 계산\n","    prediction = model(x_train)\n","\n","    # cost 계산\n","    cost = criterion(prediction, y_train)\n","\n","    # cost로 H(x) 계산\n","    optimizer.zero_grad()\n","    cost.backward()\n","    optimizer.step()\n","\n","    print(\"Epoch : {:4d}/{} Batch {}/{} Cost : {:.6f}\".format(\n","      epoch, nb_epochs, batch_idx+1, len(dataloader),\n","      cost.item()\n","    ))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K8iZrOSyKyOf"},"outputs":[],"source":["X_2 = torch.FloatTensor([[100, 70, 60], [150, 30,75]]).to(device)\n","hypothesis = model(X_2)\n","print(hypothesis)"]},{"cell_type":"markdown","metadata":{"id":"i9VfHrBASHer"},"source":["**3.CNN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mfoxQYVsSIiM"},"outputs":[],"source":["import torch\n","import torchvision.datasets as dsets\n","import torchvision.transforms as transforms\n","import torch.nn.init"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TqBdA00QSfYO"},"outputs":[],"source":["# GPU 확인\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# 랜덤 시드 고정\n","torch.manual_seed(777)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s-nuUaq6Sj0Z"},"outputs":[],"source":["learning_rate = 0.001 # 옵티마이저의 learning rate\n","training_epochs = 15 # 학습횟수\n","batch_size = 100 # minibatch 사이즈, 전체 데이터셋에서 서브 셋을 몇개로 묶을 것인지"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oYUO0kTBStGZ"},"outputs":[],"source":["mnist_train = dsets.MNIST(\n","    root=\"MNIST_data/\", # 다운로드 경로 지정\n","    train=True, # True를 지정하면 훈련 데이터로 다운로드\n","    transform=transforms.ToTensor(), # 텐서로 변환, 토치에서 알아듣는 타입으로 지정\n","    download=True\n",")\n","\n","mnist_test = dsets.MNIST(\n","    root=\"MNIST_data/\", # 다운로드 경로 지정\n","    train=False, # False를 지정하면 테스트 데이터로 다운로드\n","    transform=transforms.ToTensor(), # 텐서로 변환, 토치에서 알아듣는 타입으로 지정\n","    download=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z0haj_g6T3sT"},"outputs":[],"source":["# drop_last 마지막 남은 데이터를 버릴 것인지, 버리지 않을 것인지\n","data_loader = torch.utils.data.DataLoader(\n","    dataset=mnist_train,\n","    batch_size=batch_size,\n","    shuffle=True,\n","    drop_last=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OoecFgDdVHZK"},"outputs":[],"source":["# torch.nn.Module : PyTorch의 모든 Neural Network의 Base Class\n","class CNN(torch.nn.Module):\n","  def __init__(self):\n","    super(CNN, self).__init__()\n","    # 첫 번째 층\n","    # ImgIn shape = (?, 28, 28, 1)\n","    # Conv -> (?, 28, 28, 32)\n","    # Pool -> (?, 14, 14, 32)\n","    self.layer1 = torch.nn.Sequential(\n","        torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","    )\n","\n","    # 두 번째 층\n","    # ImgIn shape = (?, 14, 14, 32)\n","    # Conv -> (?, 14, 14, 64)\n","    # Pool -> (?, 7, 7, 64)\n","    self.layer2 = torch.nn.Sequential(\n","        torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n","        torch.nn.ReLU(),\n","        torch.nn.MaxPool2d(kernel_size=2, stride=2)\n","    )\n","\n","    # 전결합층 7x7x64 inputs -> 10 outputs\n","    self.fc = torch.nn.Linear(7 * 7 * 64, 10, bias=True)\n","\n","    # 전결합층 한정으로 가중치 초기화\n","    torch.nn.init.xavier_uniform_(self.fc.weight)\n","\n","  def forward(self, x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = out.view(out.size(0), -1) # 전결합층을 위해서 Flatten\n","    out = self.fc(out)\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AogCR2egVomE"},"outputs":[],"source":["# CNN 모델 정의\n","model = CNN().to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5J4A6H5hVpk-"},"outputs":[],"source":["# 비용 함수에 소프트맥스 함수 포함되어 있다.\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_lTtqJTUVuaQ"},"outputs":[],"source":["total_batch = len(data_loader)\n","print(\"총 배치의 수 : {}\".format(total_batch))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Q6lFH1jOXsfo"},"outputs":[],"source":["for epoch in range(training_epochs):\n","  avg_cost = 0\n","\n","  # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y는 레이블\n","  for X, Y in data_loader:\n","    # image is already size of (28x28), no reshape\n","    X = X.to(device)\n","    Y = Y.to(device)\n","\n","    optimizer.zero_grad()\n","    hypothesis = model(X)\n","    cost = criterion(hypothesis, Y)\n","    cost.backward()\n","    optimizer.step()\n","\n","    avg_cost += cost / total_batch\n","\n","  print(\"[Epoch : {:>4}] cost : {:>.9}\".format(epoch + 1, avg_cost))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ttfCVVwIX3bQ"},"outputs":[],"source":["# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n","with torch.no_grad():\n","  X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","  Y_test = mnist_test.test_labels.to(device)\n","\n","  prediction = model(X_test)\n","\n","  # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n","  correct_prediction = torch.argmax(prediction, 1) == Y_test\n","  accuracy = correct_prediction.float().mean()\n","  print(\"Accuracy :\", accuracy.item())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JUVVVOowYE_Q"},"outputs":[],"source":["# 모델 저장\n","torch.save(model.state_dict(), \"cnn_model.pt\")"]},{"cell_type":"markdown","metadata":{"id":"f_zYPXpSYGIj"},"source":["**3-1. 다시불러와서 추론 해보기**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bEVxXCpMYIJx"},"outputs":[],"source":["# 다시 불러와서 추론 해보기\n","model = CNN().to(device)\n","model.load_state_dict(torch.load(\"cnn_model.pt\"))\n","\n","# 평가 모드로 설정하여야 합니다. 이 과정을 거치지 않으면 일관성 없는 추론 결과가 출력\n","model.eval()"]},{"cell_type":"code","source":["# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n","with torch.no_grad():\n","  X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n","  Y_test = mnist_test.test_labels.to(device)\n","\n","  prediction = model(X_test)\n","  \n","  # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n","  correct_prediction = torch.argmax(prediction, 1) == Y_test\n","  accuracy = correct_prediction.float().mean()\n","\n","  print(\"Accuracy :\", accuracy.item())"],"metadata":{"id":"hLuigRbGsUVT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3-2. 이미지 불러서 추론해보기**"],"metadata":{"id":"zfI6woxdqjCL"}},{"cell_type":"code","source":["# 학습을 진행하지 않을 것이므로 torch.no_grad(), gradient descent를 하지마라고 명령내리는 것\n","from PIL import Image\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","with torch.no_grad():\n","  # 이미지 파일 경로 설정\n","  img = Image.open(\"./8.png\")\n","  \n","  transform = transforms.Compose([\n","      transforms.Grayscale(num_output_channels=1), # RGB(3D) -> Gray(2D)\n","      transforms.Resize((28, 28)), # 모델 인풋에 맞게\n","      transforms.ToTensor(), # 토치 텐서 타입으로 맞춰줘야한다.\n","  ])\n","\n","  img_tensor = transform(img).to(device) # [1, 28, 28]\n","  img_tensor = img_tensor.unsqueeze(0) # [1, 1, 28, 28] # 모델이 원래 [배치사이즈, 채널, 가로, 세로]\n","\n","  print(img_tensor.shape)\n","\n","  prediction = model(img_tensor)\n","\n","  # CNN은 10개의 아웃풋으로 각 10개의 클래스에 대한 피처값이 나온다, 이를 axis 1방향으로 max값을 찾는다는 것\n","  print('result :', torch.argmax(prediction, 1))\n","\n","  correct_prediction = torch.argmax(prediction, 1) == Y_test\n","  accuracy = correct_prediction.float().mean()\n","  \n","  print(\"Accuracy :\", accuracy.item())"],"metadata":{"id":"M94RgU-Dqnc_"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"authorship_tag":"ABX9TyOv/mGv30HfYzldpo6R9oJy"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}